// Frontend error handling utility for GPT Realtime WebRTC
// Requirements: 8.3 - éº¦å…‹é£æƒé™è¢«æ‹’ç»æ—¶æ˜¾ç¤ºæƒé™è¯·æ±‚æç¤º

// å…¨å±€AudioContextç”¨äºéŸ³é¢‘æ’­æ”¾ï¼Œé¿å…é‡å¤åˆ›å»ºå¯¼è‡´çš„å¡é¡¿
let globalAudioContext: AudioContext | null = null
// éŸ³é¢‘æ’­æ”¾é˜Ÿåˆ—ç®¡ç†
let audioPlaybackQueue: Promise<void> = Promise.resolve()
let currentAudioSource: AudioBufferSourceNode | null = null

export interface ErrorInfo {
  type: ErrorType
  code: string
  message: string
  userMessage: string
  recoverable: boolean
  timestamp: Date
}

export enum ErrorType {
  CONNECTION = 'connection_error',
  PERMISSION = 'permission_error',
  AUDIO_PLAYBACK = 'audio_playback_error',
  WEBSOCKET = 'websocket_error',
  MICROPHONE = 'microphone_error',
  NETWORK = 'network_error'
}

export class FrontendErrorHandler {
  private static instance: FrontendErrorHandler
  private errorCallbacks: Map<ErrorType, ((error: ErrorInfo) => void)[]> = new Map()

  private constructor() {}

  public static getInstance(): FrontendErrorHandler {
    if (!FrontendErrorHandler.instance) {
      FrontendErrorHandler.instance = new FrontendErrorHandler()
    }
    return FrontendErrorHandler.instance
  }

  // Handle microphone permission errors
  // Requirements: 8.3 - éº¦å…‹é£æƒé™è¢«æ‹’ç»æ—¶æ˜¾ç¤ºæƒé™è¯·æ±‚æç¤º
  public handleMicrophonePermissionError(error: DOMException): ErrorInfo {
    let userMessage = ''
    let code = 'PERMISSION_DENIED'

    switch (error.name) {
      case 'NotAllowedError':
        userMessage = 'éœ€è¦éº¦å…‹é£æƒé™æ‰èƒ½è¿›è¡Œè¯­éŸ³å¯¹è¯ã€‚è¯·ç‚¹å‡»æµè§ˆå™¨åœ°å€æ çš„éº¦å…‹é£å›¾æ ‡ï¼Œé€‰æ‹©"å…è®¸"ï¼Œç„¶ååˆ·æ–°é¡µé¢é‡è¯•ã€‚'
        code = 'MICROPHONE_PERMISSION_DENIED'
        break
      case 'NotFoundError':
        userMessage = 'æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡ã€‚è¯·ç¡®ä¿æ‚¨çš„è®¾å¤‡å·²è¿æ¥éº¦å…‹é£å¹¶é‡è¯•ã€‚'
        code = 'MICROPHONE_NOT_FOUND'
        break
      case 'NotReadableError':
        userMessage = 'æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œå¯èƒ½è¢«å…¶ä»–åº”ç”¨ç¨‹åºå ç”¨ã€‚è¯·å…³é—­å…¶ä»–ä½¿ç”¨éº¦å…‹é£çš„åº”ç”¨ç¨‹åºåé‡è¯•ã€‚'
        code = 'MICROPHONE_NOT_READABLE'
        break
      case 'OverconstrainedError':
        userMessage = 'éº¦å…‹é£ä¸æ”¯æŒæ‰€éœ€çš„éŸ³é¢‘æ ¼å¼ã€‚è¯·å°è¯•ä½¿ç”¨å…¶ä»–éº¦å…‹é£è®¾å¤‡ã€‚'
        code = 'MICROPHONE_OVERCONSTRAINED'
        break
      case 'SecurityError':
        userMessage = 'ç”±äºå®‰å…¨é™åˆ¶æ— æ³•è®¿é—®éº¦å…‹é£ã€‚è¯·ç¡®ä¿æ‚¨åœ¨å®‰å…¨çš„HTTPSç¯å¢ƒä¸­ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚'
        code = 'MICROPHONE_SECURITY_ERROR'
        break
      default:
        userMessage = 'éº¦å…‹é£è®¿é—®å¤±è´¥ï¼Œè¯·æ£€æŸ¥è®¾å¤‡è®¾ç½®åé‡è¯•ã€‚'
        code = 'MICROPHONE_UNKNOWN_ERROR'
    }

    const errorInfo: ErrorInfo = {
      type: ErrorType.PERMISSION,
      code,
      message: error.message,
      userMessage,
      recoverable: error.name === 'NotAllowedError', // æƒé™é”™è¯¯é€šå¸¸å¯ä»¥é€šè¿‡ç”¨æˆ·æ“ä½œæ¢å¤
      timestamp: new Date()
    }

    this.logError(errorInfo)
    this.triggerCallbacks(ErrorType.PERMISSION, errorInfo)
    
    return errorInfo
  }

  // Handle audio playback errors
  // Requirements: 8.4 - éŸ³é¢‘æ’­æ”¾å¤±è´¥æ—¶è®°å½•é”™è¯¯å¹¶ç»§ç»­å¤„ç†
  public handleAudioPlaybackError(error: Error, details?: string): ErrorInfo {
    const errorInfo: ErrorInfo = {
      type: ErrorType.AUDIO_PLAYBACK,
      code: 'AUDIO_PLAYBACK_FAILED',
      message: error.message,
      userMessage: 'éŸ³é¢‘æ’­æ”¾å‡ºç°é—®é¢˜ï¼Œä½†å¯¹è¯å¯ä»¥ç»§ç»­ã€‚å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·æ£€æŸ¥æ‚¨çš„éŸ³é¢‘è®¾å¤‡è®¾ç½®ã€‚',
      recoverable: true, // éŸ³é¢‘æ’­æ”¾é”™è¯¯é€šå¸¸ä¸å½±å“æ•´ä½“åŠŸèƒ½
      timestamp: new Date()
    }

    if (details) {
      console.debug('Audio playback error details:', details)
    }

    this.logError(errorInfo)
    this.triggerCallbacks(ErrorType.AUDIO_PLAYBACK, errorInfo)
    
    return errorInfo
  }

  // Handle WebSocket connection errors
  // Requirements: 8.1 - WebSocketè¿æ¥æ–­å¼€æ—¶å°è¯•è‡ªåŠ¨é‡è¿
  public handleWebSocketError(error: Event | Error, endpoint?: string): ErrorInfo {
    let message = 'WebSocket connection error'
    let userMessage = 'ç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜ï¼Œæ­£åœ¨å°è¯•é‡æ–°è¿æ¥...'
    
    if (error instanceof Error) {
      message = error.message
    } else if (error.type) {
      message = `WebSocket ${error.type} event`
    }

    const errorInfo: ErrorInfo = {
      type: ErrorType.WEBSOCKET,
      code: 'WEBSOCKET_CONNECTION_ERROR',
      message,
      userMessage,
      recoverable: true, // WebSocketé”™è¯¯é€šå¸¸å¯ä»¥é€šè¿‡é‡è¿æ¢å¤
      timestamp: new Date()
    }

    if (endpoint) {
      console.debug('WebSocket error endpoint:', endpoint)
    }

    this.logError(errorInfo)
    this.triggerCallbacks(ErrorType.WEBSOCKET, errorInfo)
    
    return errorInfo
  }

  // Handle network errors
  public handleNetworkError(error: Error): ErrorInfo {
    const errorInfo: ErrorInfo = {
      type: ErrorType.NETWORK,
      code: 'NETWORK_ERROR',
      message: error.message,
      userMessage: 'ç½‘ç»œè¿æ¥ä¸ç¨³å®šï¼Œè¯·æ£€æŸ¥æ‚¨çš„ç½‘ç»œè¿æ¥åé‡è¯•ã€‚',
      recoverable: true,
      timestamp: new Date()
    }

    this.logError(errorInfo)
    this.triggerCallbacks(ErrorType.NETWORK, errorInfo)
    
    return errorInfo
  }

  // Create user-friendly error messages
  // Requirements: 8.5 - æä¾›ç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
  public createUserFriendlyMessage(errorType: ErrorType, originalMessage?: string): string {
    switch (errorType) {
      case ErrorType.CONNECTION:
        return 'ç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜ï¼Œæ­£åœ¨å°è¯•é‡æ–°è¿æ¥...'
      case ErrorType.PERMISSION:
        return 'éœ€è¦éº¦å…‹é£æƒé™æ‰èƒ½è¿›è¡Œè¯­éŸ³å¯¹è¯ï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­å…è®¸éº¦å…‹é£è®¿é—®'
      case ErrorType.AUDIO_PLAYBACK:
        return 'éŸ³é¢‘æ’­æ”¾å‡ºç°é—®é¢˜ï¼Œä½†å¯¹è¯å¯ä»¥ç»§ç»­'
      case ErrorType.WEBSOCKET:
        return 'è¿æ¥å·²æ–­å¼€ï¼Œæ­£åœ¨å°è¯•é‡æ–°è¿æ¥...'
      case ErrorType.MICROPHONE:
        return 'éº¦å…‹é£è®¿é—®å¤±è´¥ï¼Œè¯·æ£€æŸ¥è®¾å¤‡è®¾ç½®'
      case ErrorType.NETWORK:
        return 'ç½‘ç»œè¿æ¥ä¸ç¨³å®šï¼Œè¯·æ£€æŸ¥æ‚¨çš„ç½‘ç»œè¿æ¥'
      default:
        return originalMessage || 'å‘ç”Ÿäº†æœªçŸ¥é”™è¯¯ï¼Œè¯·é‡è¯•'
    }
  }

  // Register error callback
  public onError(errorType: ErrorType, callback: (error: ErrorInfo) => void): void {
    if (!this.errorCallbacks.has(errorType)) {
      this.errorCallbacks.set(errorType, [])
    }
    this.errorCallbacks.get(errorType)!.push(callback)
  }

  // Remove error callback
  public offError(errorType: ErrorType, callback: (error: ErrorInfo) => void): void {
    const callbacks = this.errorCallbacks.get(errorType)
    if (callbacks) {
      const index = callbacks.indexOf(callback)
      if (index > -1) {
        callbacks.splice(index, 1)
      }
    }
  }

  // Trigger error callbacks
  private triggerCallbacks(errorType: ErrorType, errorInfo: ErrorInfo): void {
    const callbacks = this.errorCallbacks.get(errorType)
    if (callbacks) {
      callbacks.forEach(callback => {
        try {
          callback(errorInfo)
        } catch (err) {
          console.error('Error in error callback:', err)
        }
      })
    }
  }

  // Log error information
  private logError(errorInfo: ErrorInfo): void {
    console.error(`[${errorInfo.type}:${errorInfo.code}] ${errorInfo.message}`)
    console.error(`User message: ${errorInfo.userMessage}`)
    console.error(`Recoverable: ${errorInfo.recoverable}`)
    console.error(`Timestamp: ${errorInfo.timestamp.toISOString()}`)
  }

  // Check if error is recoverable
  public isRecoverable(errorInfo: ErrorInfo): boolean {
    return errorInfo.recoverable
  }

  // Show permission request dialog
  public showPermissionRequestDialog(): void {
    const message = `
      è¯­éŸ³å¯¹è¯åŠŸèƒ½éœ€è¦è®¿é—®æ‚¨çš„éº¦å…‹é£ã€‚
      
      è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å¯ç”¨éº¦å…‹é£æƒé™ï¼š
      1. ç‚¹å‡»æµè§ˆå™¨åœ°å€æ å·¦ä¾§çš„é”å½¢å›¾æ ‡æˆ–éº¦å…‹é£å›¾æ ‡
      2. é€‰æ‹©"å…è®¸"éº¦å…‹é£è®¿é—®
      3. åˆ·æ–°é¡µé¢é‡è¯•
      
      å¦‚æœä»ç„¶æ— æ³•ä½¿ç”¨ï¼Œè¯·æ£€æŸ¥æ‚¨çš„æµè§ˆå™¨è®¾ç½®ä¸­æ˜¯å¦å…è®¸æ­¤ç½‘ç«™è®¿é—®éº¦å…‹é£ã€‚
    `
    
    alert(message)
  }

  // Retry mechanism for recoverable errors
  public async retryOperation<T>(
    operation: () => Promise<T>,
    maxRetries: number = 3,
    delay: number = 1000
  ): Promise<T> {
    let lastError: Error
    
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        return await operation()
      } catch (error) {
        lastError = error as Error
        console.warn(`Operation failed (attempt ${attempt}/${maxRetries}):`, error)
        
        if (attempt < maxRetries) {
          await new Promise(resolve => setTimeout(resolve, delay * attempt))
        }
      }
    }
    
    throw lastError!
  }
}

// Export singleton instance
export const errorHandler = FrontendErrorHandler.getInstance()

// Utility functions for common error scenarios
export const handleMicrophonePermission = async (): Promise<MediaStream> => {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        sampleRate: 24000,  // æ›´æ–°ä¸º24kHzä»¥åŒ¹é…GPTè¦æ±‚
        channelCount: 1,
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      }
    })
    return stream
  } catch (error) {
    const errorInfo = errorHandler.handleMicrophonePermissionError(error as DOMException)
    
    if (errorInfo.code === 'MICROPHONE_PERMISSION_DENIED') {
      errorHandler.showPermissionRequestDialog()
    }
    
    throw error
  }
}

export const handleAudioPlayback = async (audioData: string): Promise<void> => {
  // å°†éŸ³é¢‘æ’­æ”¾åŠ å…¥é˜Ÿåˆ—ï¼Œé¿å…é‡å æ’­æ”¾
  audioPlaybackQueue = audioPlaybackQueue.then(async () => {
    try {
      // åœæ­¢å½“å‰æ’­æ”¾çš„éŸ³é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
      if (currentAudioSource) {
        currentAudioSource.stop()
        currentAudioSource = null
      }
      
      // Decode base64 audio data
      const binaryData = atob(audioData)
      const arrayBuffer = new ArrayBuffer(binaryData.length)
      const uint8Array = new Uint8Array(arrayBuffer)
      
      for (let i = 0; i < binaryData.length; i++) {
        uint8Array[i] = binaryData.charCodeAt(i)
      }

      // ä½¿ç”¨å…¨å±€AudioContexté¿å…é‡å¤åˆ›å»º
      if (!globalAudioContext) {
        globalAudioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
          sampleRate: 24000 // GPT uses 24kHz
        })
      }
      
      // ç¡®ä¿AudioContextå¤„äºè¿è¡ŒçŠ¶æ€
      if (globalAudioContext.state === 'suspended') {
        await globalAudioContext.resume()
      }
      
      // Convert PCM16 bytes to Float32 samples
      const pcm16Data = new Int16Array(arrayBuffer)
      const originalSampleCount = pcm16Data.length
      
      if (originalSampleCount === 0) {
        console.warn('Empty audio data received, skipping playback')
        return
      }
      
      // æ·»åŠ é™éŸ³å¡«å……ä»¥å‡å°‘çˆ†ç ´éŸ³ï¼ˆå¼€å¤´å’Œç»“å°¾å„æ·»åŠ 240ä¸ªæ ·æœ¬ï¼Œçº¦10msï¼‰
      const paddingSamples = 240 // 10ms at 24kHz
      const totalSampleCount = originalSampleCount + (paddingSamples * 2)
      const audioBuffer = globalAudioContext.createBuffer(1, totalSampleCount, 24000) // mono, 24kHz
      const channelData = audioBuffer.getChannelData(0)
      
      // å¼€å¤´é™éŸ³å¡«å……
      for (let i = 0; i < paddingSamples; i++) {
        channelData[i] = 0
      }
      
      // Convert PCM16 to Float32 (-1 to 1 range) with better precision
      for (let i = 0; i < originalSampleCount; i++) {
        channelData[i + paddingSamples] = Math.max(-1, Math.min(1, pcm16Data[i] / 32768.0))
      }
      
      // ç»“å°¾é™éŸ³å¡«å……
      for (let i = originalSampleCount + paddingSamples; i < totalSampleCount; i++) {
        channelData[i] = 0
      }
      
      // åˆ›å»ºéŸ³é¢‘æºå¹¶æ’­æ”¾
      const source = globalAudioContext.createBufferSource()
      source.buffer = audioBuffer
      currentAudioSource = source
      
      // æ·»åŠ éŸ³é‡æ§åˆ¶å’Œä½é€šæ»¤æ³¢å™¨å‡å°‘å™ªéŸ³
      const gainNode = globalAudioContext.createGain()
      const filterNode = globalAudioContext.createBiquadFilter()
      
      gainNode.gain.value = 0.7 // é€‚ä¸­çš„éŸ³é‡
      filterNode.type = 'lowpass'
      filterNode.frequency.value = 8000 // 8kHzä½é€šæ»¤æ³¢ï¼Œå»é™¤é«˜é¢‘å™ªéŸ³
      filterNode.Q.value = 1
      
      // æ·»åŠ æ·¡å…¥æ·¡å‡ºæ•ˆæœé¿å…çˆ†ç ´éŸ³
      const fadeTime = 0.01 // 10msæ·¡å…¥æ·¡å‡º
      const currentTime = globalAudioContext.currentTime
      
      // æ·¡å…¥æ•ˆæœ
      gainNode.gain.setValueAtTime(0, currentTime)
      gainNode.gain.linearRampToValueAtTime(0.7, currentTime + fadeTime)
      
      // æ·¡å‡ºæ•ˆæœï¼ˆåœ¨éŸ³é¢‘ç»“æŸå‰ï¼‰
      const audioEndTime = currentTime + audioBuffer.duration
      gainNode.gain.setValueAtTime(0.7, audioEndTime - fadeTime)
      gainNode.gain.linearRampToValueAtTime(0, audioEndTime)
      
      source.connect(filterNode)
      filterNode.connect(gainNode)
      gainNode.connect(globalAudioContext.destination)
      
      // è¿”å›Promiseä»¥ä¾¿ç­‰å¾…æ’­æ”¾å®Œæˆ
      return new Promise<void>((resolve, reject) => {
        source.onended = () => {
          console.log(`âœ“ GPT audio playback completed: ${audioBuffer.duration.toFixed(2)}s`)
          currentAudioSource = null
          resolve()
        }
        
        try {
          source.start()
          console.log(`ğŸ”Š Playing GPT audio: ${originalSampleCount} samples (${totalSampleCount} with padding), ${audioBuffer.duration.toFixed(2)}s`)
          
          // è®¾ç½®è¶…æ—¶ä»¥é˜²éŸ³é¢‘å¡ä½
          setTimeout(() => {
            if (currentAudioSource === source) {
              console.warn('Audio playback timeout, stopping source')
              try {
                source.stop()
              } catch (e) {
                console.warn('Error stopping timed out audio source:', e)
              }
              currentAudioSource = null
              resolve()
            }
          }, audioBuffer.duration * 1000 + 1000) // éŸ³é¢‘æ—¶é•¿ + 1ç§’ç¼“å†²
          
        } catch (error) {
          console.error('Failed to start audio source:', error)
          currentAudioSource = null
          reject(error)
        }
      })
      
    } catch (error) {
      errorHandler.handleAudioPlaybackError(error as Error, `Failed to play PCM16 audio data of length ${audioData.length}`)
      throw error
    }
  })
  
  return audioPlaybackQueue
}

// æ¸…ç†éŸ³é¢‘èµ„æº
export const cleanupAudioResources = (): void => {
  if (currentAudioSource) {
    try {
      currentAudioSource.stop()
    } catch (error) {
      console.warn('Error stopping current audio source:', error)
    }
    currentAudioSource = null
  }
  
  if (globalAudioContext && globalAudioContext.state !== 'closed') {
    try {
      globalAudioContext.close()
    } catch (error) {
      console.warn('Error closing global audio context:', error)
    }
    globalAudioContext = null
  }
  
  // é‡ç½®æ’­æ”¾é˜Ÿåˆ—
  audioPlaybackQueue = Promise.resolve()
}